{"cells":[{"cell_type":"markdown","source":["### Preparation: 1. Read file function from professor's lecture content"],"metadata":{}},{"cell_type":"code","source":["# read only cell\n\nimport os\n\n# get the databricks runtime version\ndb_env = os.getenv(\"DATABRICKS_RUNTIME_VERSION\")\n\n# Define a function to read the data file.  The full path data file name is constructed\n# by checking runtime environment variables to determine if the runtime environment is \n# databricks, or a student's personal computer.  The full path file name is then\n# constructed based on the runtime env.\n# \n# Params\n#   data_file_name: The base name of the data file to load\n# \n# Returns the full path file name based on the runtime env\n#\ndef get_training_filename(data_file_name):    \n    # if the databricks env var exists\n    if db_env != None:\n        # build the full path file name assuming data brick env\n        full_path_name = \"/FileStore/tables/%s\" % data_file_name\n    # else the data is assumed to be in the same dir as this notebook\n    else:\n        # Assume the student is running on their own computer and load the data\n        # file from the same dir as this notebook\n        full_path_name = data_file_name\n    \n    # return the full path file name to the caller\n    return full_path_name"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"markdown","source":["###  Preparation: 2. import neccessary packages and functions"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.ml import feature\nfrom pyspark.ml import classification\nfrom pyspark.sql import functions as fn\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator, \\\n    MulticlassClassificationEvaluator, \\\n    RegressionEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import Row\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nspark = SparkSession.builder.getOrCreate()\nsc = spark.sparkContext"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["## Part 1: Exploring\n\n- Data Resource\n[https://www.kaggle.com/pitasr/falldata](https://www.kaggle.com/pitasr/falldata)\n\n- Attribute Description:\n\n  - ACTIVITY    :   activity classification  \n      - 0- Standing 1- Walking 2- Sitting 3- Falling 4- Cramps 5- Running\n  - TIME        :   monitoring time\n  - SL          :  sugar level\n  - EEGEEG      :  monitoring rate\n  - BP          :  Blood pressure\n  - HR          :  Heart beat rate\n  - CIRCLUATION :  Blood circulation"],"metadata":{}},{"cell_type":"code","source":["# Read file from csv file\ndf = spark.read.csv(get_training_filename('falldeteciton.csv'), header=True, inferSchema=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["#1. Show first 10 rows\ndf.show(10)\n\n#2. Print the shape of df (num_rows, num_cols)\nprint(df.count(),len(df.columns))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-------+--------+--------+---+---+-----------+\nACTIVITY|   TIME|      SL|     EEG| BP| HR|CIRCLUATION|\n+--------+-------+--------+--------+---+---+-----------+\n       3|4722.92| 4019.64| -1600.0| 13| 79|        317|\n       2|4059.12| 2191.03|-1146.08| 20| 54|        165|\n       2|4773.56| 2787.99|-1263.38| 46| 67|        224|\n       4|8271.27| 9545.98|-2848.93| 26|138|        554|\n       4|7102.16| 14148.8|-2381.15| 85|120|        809|\n       5|7015.24| 7336.79| -1699.8| 22| 95|        427|\n       3|8620.28| 24949.9|-3198.06| 35|157|       1519|\n       3|9238.73| 39245.5| -2590.0| 15|196|       1885|\n       0|12276.4| 59742.0| -5101.0| 56|249|       2826|\n       4|14165.5|140950.0| -1410.0| 82|315|       5844|\n+--------+-------+--------+--------+---+---+-----------+\nonly showing top 10 rows\n\n16382 7\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["# 3. Check Missing Values\nfrom pyspark.sql.functions import col,sum\ndf.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns)).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+----+---+---+---+---+-----------+\nACTIVITY|TIME| SL|EEG| BP| HR|CIRCLUATION|\n+--------+----+---+---+---+---+-----------+\n       0|   0|  0|  0|  0|  0|          0|\n+--------+----+---+---+---+---+-----------+\n\n</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["## Part2: Visualization"],"metadata":{}},{"cell_type":"code","source":["#1. histgram\npd_df = df.toPandas()\nhelp(plt.subplots)\nfig, ax = plt.subplots()\nax = sns.distplot(pd_df['ACTIVITY'], kde=True)\nfig.set_size_inches(5,5)\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#  histgrams of atttibutes\nfig = plt.figure(figsize=(18,9))\n\nplt.subplot(231)\nsns.distplot(pd_df['TIME'])\nplt.title('TIME distribution')\n\nplt.subplot(232)\nsns.distplot(pd_df['SL'])\nplt.title('SL distribution')\n\nplt.subplot(233)\nsns.distplot(pd_df['EEG'])\nplt.title('EEG distribution')\n\nplt.subplot(234)\nsns.distplot(pd_df['BP'])\nplt.title('BP distribution')\n\nplt.subplot(235)\nsns.distplot(pd_df['HR'])\nplt.title('HR distribution')\n\nplt.subplot(236)\nsns.distplot(pd_df['CIRCLUATION'])\nplt.title('CIRCLUATION distribution')\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["#2. Pairplot\nax=sns.pairplot(pd_df[['TIME', 'SL', 'EEG', 'BP', 'HR','CIRCLUATION']], diag_kind = 'kde',\n             plot_kws = {'alpha': 0.7, 's': 18, 'edgecolor': 'None'},\n             height = 4)\nax.fig.suptitle(\"Data Pair Plot\", y=1.01)\nax.fig.set_size_inches(12,12)\ndisplay(ax.fig)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["#3. Box plot : Time\nfig, ax = plt.subplots()\nfig = pd_df.boxplot(column = 'TIME',by='ACTIVITY') \nfig.set_xticklabels(['Standing', 'Walking', 'Sitting', 'Falling','Cramps','Running'])\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["#4. Box plot : SL\nfig, ax = plt.subplots()\nfig = pd_df.boxplot(column = 'SL',by='ACTIVITY') \nfig.set_xticklabels(['Standing', 'Walking', 'Sitting', 'Falling','Cramps','Running'])\ndisplay(fig)\n"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["#5. Box plot : Circulation\nfig, ax = plt.subplots()\nfig = pd_df.boxplot(column = 'CIRCLUATION',by='ACTIVITY') \nfig.set_xticklabels(['Standing', 'Walking', 'Sitting', 'Falling','Cramps','Running'])\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["#6. Scatter plot\nax = sns.FacetGrid(pd_df, col=\"ACTIVITY\") \nax.map(plt.scatter, \"TIME\", \"SL\")\nax.fig.suptitle(\"Fall Detection\", y=1.01)\nax.fig.set_size_inches(20,10)\ndisplay(ax.fig)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["## Part2. Preprocessing"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.functions import udf,col\nfrom pyspark.sql.types import IntegerType\n\n# 1. Transform the target variable into 2 classes: 1(falling) or 0(other activity)\ndef func(s):\n  if s == 3:\n    return 1\n  else:\n    return 0\nmy_func = udf(func,IntegerType())\ndf_fall = df.withColumn('FALL', my_func('ACTIVITY'))\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["# 2. Split the dataset with the split ratio 8:2\n\ntraining, test = df_fall.randomSplit([0.8, 0.2], 0)\ntraining.groupBy('FALL').agg(fn.count('*')).show()\ntest.groupBy('FALL').agg(fn.count('*')).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+--------+\nFALL|count(1)|\n+----+--------+\n   1|    2910|\n   0|   10208|\n+----+--------+\n\n+----+--------+\nFALL|count(1)|\n+----+--------+\n   1|     678|\n   0|    2586|\n+----+--------+\n\n</div>"]}}],"execution_count":19},{"cell_type":"markdown","source":["## Part4: Modeling and Evaluation"],"metadata":{}},{"cell_type":"markdown","source":["### 4.1 Logistic Regression"],"metadata":{}},{"cell_type":"code","source":["# logistic regression pipeline\n\nva = feature.VectorAssembler(inputCols=['TIME', 'SL', 'EEG', 'BP', 'HR','CIRCLUATION'],\n                                        outputCol='features')\nst = feature.StandardScaler(withMean=True, inputCol='features')\nlr = classification.LogisticRegression(labelCol='FALL', featuresCol='features')\nmodel1 = Pipeline(stages=[va,lr])\n\nmodel1_fitted = model1.fit(training)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"code","source":["# check the AUC score\nfrom pyspark.ml import evaluation\nevaluator = evaluation.MulticlassClassificationEvaluator(metricName=\"accuracy\",labelCol='FALL')\nbce = BinaryClassificationEvaluator(labelCol='FALL')\nbce.evaluate(model1_fitted.transform(test))\nprint(\"Test Area Under ROC: \" + str(bce.evaluate(model1_fitted.transform(test), {bce.metricName: \"areaUnderROC\"})))\n\nprint(\"accuracy: \" + str(evaluator.evaluate(model1_fitted.transform(test), {evaluator.metricName: \"accuracy\"})))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test Area Under ROC: 0.6077266515637881\naccuracy: 0.7935049019607843\n</div>"]}}],"execution_count":23},{"cell_type":"code","source":["# Grid search to tune the model\nfrom pyspark.ml.tuning import CrossValidator\nfrom pyspark.ml.tuning import ParamGridBuilder\nimport numpy as np\n\nparamGrid = ParamGridBuilder()\\\n    .addGrid(lr.regParam, [0., 0.015, 0.025, 0.05]) \\\n    .addGrid(lr.fitIntercept, [False, True])\\\n    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n    .build()\nlr = classification.LogisticRegression(labelCol='FALL', featuresCol='features')\n\nbce = BinaryClassificationEvaluator(labelCol='FALL')\n\nlr_cv = CrossValidator(estimator=lr, evaluator=bce,estimatorParamMaps=paramGrid,numFolds=3)\n\nlr_cv_model =  Pipeline(stages=[va,lr_cv]).fit(training)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n</div>"]}}],"execution_count":24},{"cell_type":"code","source":["# check the AUC score again\nprint(\"Test Area Under ROC: \" + str(bce.evaluate(lr_cv_model.transform(test), {bce.metricName: \"areaUnderROC\"})))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test Area Under ROC: 0.6077266515637881\n</div>"]}}],"execution_count":25},{"cell_type":"code","source":["# ROC scatter Plot\nimport matplotlib.pyplot as plt\nimport numpy as np\ntpr_fpr = lr_cv_model.stages[-1].bestModel.summary.roc.toPandas()\nfig, ax = plt.subplots()\nX = np.linspace(0,1,10)\nplt.plot( X, X, color = 'black', linewidth=2, linestyle=\"-\" )\nplt.scatter(tpr_fpr['FPR'],tpr_fpr['TPR'],color = 'blue',s=14,alpha=0.6)\nplt.xlim(0,1)\nplt.ylim(0,1)\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('ROC scatter plot')\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["bestLRModel = lr_cv_model.stages[-1].bestModel\nparam_dict = bestLRModel.extractParamMap()\nname_dict = {}\nfor k, v in param_dict.items():\n  name_dict[k.name] = v\nbest_reg = name_dict[\"regParam\"]\nbest_elastic_net = name_dict[\"elasticNetParam\"]\nprint('Best Param (regParam):{:.4f} '.format(best_reg))\nprint('Best Param (elasticNetParam):{:.4f} '.format(best_elastic_net))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Best Param (regParam):0.0000 \nBest Param (elasticNetParam):0.0000 \n</div>"]}}],"execution_count":27},{"cell_type":"markdown","source":["### 4.2 SVM (Support Vector Machine)"],"metadata":{}},{"cell_type":"code","source":["# SVM\nfrom pyspark.ml.classification import LinearSVC\nsvm = LinearSVC(labelCol='FALL',maxIter=50, regParam=0.01)\n\nsvm_pipeline = Pipeline(stages=[va,st,svm])\n\nsvm_pipeline_fitted = svm_pipeline.fit(training)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":29},{"cell_type":"code","source":["# check result\nprint(\"Test Area Under ROC: \" + str(bce.evaluate(svm_pipeline_fitted.transform(test), {bce.metricName: \"areaUnderROC\"})))\nprint(\"accuracy: \" + str(evaluator.evaluate(svm_pipeline_fitted.transform(test), {evaluator.metricName: \"accuracy\"})))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test Area Under ROC: 0.5163011861007867\naccuracy: 0.7922794117647058\n</div>"]}}],"execution_count":30},{"cell_type":"markdown","source":["### 4.3 Decistion Tree"],"metadata":{}},{"cell_type":"code","source":["#2.1 decision tree (DT)\nfrom pyspark.ml.classification import DecisionTreeClassifier\ndt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'FALL', maxDepth =5)\n\ndt_pipeline = Pipeline(stages=[va,dt])\n\ndt_pipeline_fitted = dt_pipeline.fit(training)\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":32},{"cell_type":"code","source":["print(\"Test Area Under ROC: \" + str(bce.evaluate(dt_pipeline_fitted.transform(test), {bce.metricName: \"areaUnderROC\"})))\nprint(\"accuracy: \" + str(evaluator.evaluate(dt_pipeline_fitted.transform(test), {evaluator.metricName: \"accuracy\"})))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test Area Under ROC: 0.5874039244673498\naccuracy: 0.8051470588235294\n</div>"]}}],"execution_count":33},{"cell_type":"code","source":["display(dt_pipeline_fitted.stages[-1])\n# feature 1-6: 'TIME', 'SL', 'EEG', 'BP', 'HR', 'CIRCLUATION'"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>treeNode</th></tr></thead><tbody><tr><td>{\"index\":23,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":101.5,\"categories\":null,\"feature\":3,\"overflow\":false}</td></tr><tr><td>{\"index\":11,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":515.5,\"categories\":null,\"feature\":5,\"overflow\":false}</td></tr><tr><td>{\"index\":5,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":75.5,\"categories\":null,\"feature\":4,\"overflow\":false}</td></tr><tr><td>{\"index\":1,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":165.5,\"categories\":null,\"feature\":5,\"overflow\":false}</td></tr><tr><td>{\"index\":0,\"featureType\":null,\"prediction\":0.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":3,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":2199.3950000000004,\"categories\":null,\"feature\":1,\"overflow\":false}</td></tr><tr><td>{\"index\":2,\"featureType\":null,\"prediction\":1.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":4,\"featureType\":null,\"prediction\":0.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":7,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":47.5,\"categories\":null,\"feature\":3,\"overflow\":false}</td></tr><tr><td>{\"index\":6,\"featureType\":null,\"prediction\":0.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":9,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":63.5,\"categories\":null,\"feature\":3,\"overflow\":false}</td></tr><tr><td>{\"index\":8,\"featureType\":null,\"prediction\":1.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":10,\"featureType\":null,\"prediction\":0.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":17,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":-3329.55,\"categories\":null,\"feature\":2,\"overflow\":false}</td></tr><tr><td>{\"index\":15,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":2061.5,\"categories\":null,\"feature\":5,\"overflow\":false}</td></tr><tr><td>{\"index\":13,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":115.5,\"categories\":null,\"feature\":4,\"overflow\":false}</td></tr><tr><td>{\"index\":12,\"featureType\":null,\"prediction\":1.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":14,\"featureType\":null,\"prediction\":0.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":16,\"featureType\":null,\"prediction\":0.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":19,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":1747.5,\"categories\":null,\"feature\":5,\"overflow\":false}</td></tr><tr><td>{\"index\":18,\"featureType\":null,\"prediction\":0.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":21,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":27.5,\"categories\":null,\"feature\":3,\"overflow\":false}</td></tr><tr><td>{\"index\":20,\"featureType\":null,\"prediction\":1.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":22,\"featureType\":null,\"prediction\":0.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":29,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":-1522.545,\"categories\":null,\"feature\":2,\"overflow\":false}</td></tr><tr><td>{\"index\":27,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":1747.5,\"categories\":null,\"feature\":5,\"overflow\":false}</td></tr><tr><td>{\"index\":25,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":5156.71,\"categories\":null,\"feature\":0,\"overflow\":false}</td></tr><tr><td>{\"index\":24,\"featureType\":null,\"prediction\":1.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":26,\"featureType\":null,\"prediction\":0.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":28,\"featureType\":null,\"prediction\":0.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":35,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":4752.59,\"categories\":null,\"feature\":1,\"overflow\":false}</td></tr><tr><td>{\"index\":33,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":4244.465,\"categories\":null,\"feature\":1,\"overflow\":false}</td></tr><tr><td>{\"index\":31,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":-1286.945,\"categories\":null,\"feature\":2,\"overflow\":false}</td></tr><tr><td>{\"index\":30,\"featureType\":null,\"prediction\":0.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":32,\"featureType\":null,\"prediction\":1.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":34,\"featureType\":null,\"prediction\":1.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":37,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":51075.55,\"categories\":null,\"feature\":1,\"overflow\":false}</td></tr><tr><td>{\"index\":36,\"featureType\":null,\"prediction\":0.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":39,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":10467.0,\"categories\":null,\"feature\":0,\"overflow\":false}</td></tr><tr><td>{\"index\":38,\"featureType\":null,\"prediction\":1.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":40,\"featureType\":null,\"prediction\":0.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr></tbody></table></div>"]}}],"execution_count":34},{"cell_type":"code","source":["#maxDepth 30\ndt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'FALL', maxDepth =30)\n\ndt_pipeline_30 = Pipeline(stages=[va,dt])\n\ndt_pipeline_fitted_30 = dt_pipeline_30.fit(training)\nprint(\"Test Area Under ROC: \" + str(bce.evaluate(dt_pipeline_fitted_30.transform(test), {bce.metricName: \"areaUnderROC\"})))\nprint(\"accuracy: \" + str(evaluator.evaluate(dt_pipeline_fitted_30.transform(test), {evaluator.metricName: \"accuracy\"})))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test Area Under ROC: 0.7364413440194192\naccuracy: 0.821078431372549\n</div>"]}}],"execution_count":35},{"cell_type":"markdown","source":["### 4.4 Random Forest"],"metadata":{}},{"cell_type":"code","source":["# random forest\nfrom pyspark.ml.classification import RandomForestClassifier\nrf = RandomForestClassifier(featuresCol = 'features', labelCol = 'FALL')\nrf_pipeline = Pipeline(stages=[va,st,rf])\n\nrf_pipeline_fitted = rf_pipeline.fit(training)\nbce = BinaryClassificationEvaluator(labelCol='FALL')\nprint(\"Test Area Under ROC: \" + str(bce.evaluate(rf_pipeline_fitted.transform(test), {bce.metricName: \"areaUnderROC\"})))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test Area Under ROC: 0.7306243398193586\n</div>"]}}],"execution_count":37},{"cell_type":"code","source":["# grid search\nfrom pyspark.ml.tuning import CrossValidator\nfrom pyspark.ml.tuning import ParamGridBuilder\nparamGrid = ParamGridBuilder() \\\n    .addGrid(rf.numTrees, [int(x) for x in np.linspace(start = 100, stop = 200, num = 5)]) \\\n    .addGrid(rf.maxDepth, [int(x) for x in np.linspace(start = 8, stop = 25, num = 3)]) \\\n    .build()\n\nbce = BinaryClassificationEvaluator(labelCol='FALL')\n\ncv = CrossValidator(estimator=Pipeline(stages=[va, rf]), evaluator=bce,estimatorParamMaps=paramGrid,numFolds=3)\n\nrn_cv_model = cv.fit(training)\n\n\n# best hyperparameters:  numTree : 150. maxDepth:16"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n</div>"]}}],"execution_count":38},{"cell_type":"code","source":["print(\"Test Area Under ROC: \" + str(bce.evaluate(rn_cv_model.transform(test), {bce.metricName: \"areaUnderROC\"})))"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["# fast run( with best hyperparameters)\nrf = RandomForestClassifier(featuresCol = 'features', labelCol = 'FALL',numTrees=150,maxDepth=16)\nrf_pipeline_best = Pipeline(stages=[va,st,rf])\n\nrf_pipeline_best_fitted = rf_pipeline_best.fit(training)\nbce = BinaryClassificationEvaluator(labelCol='FALL')\nprint(\"Test Area Under ROC: \" + str(bce.evaluate(rf_pipeline_best_fitted.transform(test), {bce.metricName: \"areaUnderROC\"})))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test Area Under ROC: 0.8941021771417306\n</div>"]}}],"execution_count":40},{"cell_type":"code","source":["print(\"accuracy: \" + str(evaluator.evaluate(rf_pipeline_best_fitted.transform(test), {evaluator.metricName: \"accuracy\"})))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">accuracy: 0.8526348039215687\n</div>"]}}],"execution_count":41},{"cell_type":"code","source":["# Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\ny_true = test.select(\"FALL\")\ny_true = y_true.toPandas()\n\ny_pred = rf_pipeline_best_fitted.transform(test).select(\"prediction\")\ny_pred = y_pred.toPandas()\n\nc_matrix = confusion_matrix(y_true, y_pred)\nprint(f1_score(y_true, y_pred))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0.6203630623520127\n</div>"]}}],"execution_count":42},{"cell_type":"code","source":["# confusion matrix visulization function\n# Method from https://stackoverflow.com/questions/19233771/sklearn-plot-confusion-matrix-with-labels\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.bone_r):\n\n    print('Confusion matrix')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":43},{"cell_type":"code","source":["# Plot the Confusion Matrix\n\nclass_names = [\"No\",\"Yes\"]\n\nfig = plt.figure()\nplot_confusion_matrix(c_matrix, classes=class_names,\n                      title='Confusion matrix')\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["# Extract Feature Importance\ndef ExtractFeatureImp(featureImp, dataset, featuresCol):\n  list_extract = []\n  for i in dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"]:\n    list_extract = list_extract + dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"][i]\n  varlist = pd.DataFrame(list_extract)\n  varlist['score'] = varlist['idx'].apply(lambda x: featureImp[x])\n  return(varlist.sort_values('score', ascending = False))\n\nfeature_importance_rf=ExtractFeatureImp(rn_cv_model.bestModel.stages[-1].featureImportances,va.transform(df_fall),\"features\").head(20)\nfeature_importance_rf"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["# Plot the feature importance\nsns_plot = sns.barplot(x = feature_importance_rf['score'], y = feature_importance_rf['name'],palette=sns.color_palette(\"Set2\", 6))\ndisplay(sns_plot)"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":["### 4.5 Gradient-Boosted Tree"],"metadata":{}},{"cell_type":"code","source":["# Gradient-Boosted Tree Classifier\nfrom pyspark.ml.classification import GBTClassifier\ngbt = GBTClassifier(maxIter=10,labelCol = 'FALL')\n\ngbt_pipeline = Pipeline(stages=[va,st,gbt])\n\ngbt_pipeline_fitted = gbt_pipeline.fit(training)\n\nprint(\"Test Area Under ROC: \" + str(bce.evaluate(gbt_pipeline_fitted.transform(test), {bce.metricName: \"areaUnderROC\"})))\nprint(\"accuracy: \" + str(evaluator.evaluate(gbt_pipeline_fitted.transform(test), {evaluator.metricName: \"accuracy\"})))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test Area Under ROC: 0.8094399272689106\naccuracy: 0.8112745098039216\n</div>"]}}],"execution_count":48},{"cell_type":"code","source":["#grid search\nparamGrid = ParamGridBuilder() \\\n    .addGrid(gbt.minInfoGain, [int(x) for x in np.linspace(start = 0, stop = 3, num = 1)]) \\\n    .addGrid(gbt.maxDepth, [int(x) for x in np.linspace(start = 5, stop = 25, num = 3)]) \\\n    .build()\n\n\nbce = BinaryClassificationEvaluator(labelCol='FALL')\n\ngbt_cv = CrossValidator(estimator=Pipeline(stages=[va,st, gbt]), evaluator=bce,estimatorParamMaps=paramGrid,numFolds=3)\n\ngbt_model = gbt_cv.fit(training)"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["# auc score\nprint(\"Test Area Under ROC: \" + str(bce.evaluate(gbt_model.transform(test), {bce.metricName: \"areaUnderROC\"})))\n"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["# Extract feature importance\nfeature_importance_gbt=ExtractFeatureImp(gbt_model.bestModel.stages[-1].featureImportances,va.transform(df_fall),\"features\").head(20)\nfeature_importance_gbt"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["# Plot feature importance\nsns_plot = sns.barplot(x = feature_importance_rf['score'], y = feature_importance_rf['name'],palette=sns.color_palette(\"Set2\", 6))\ndisplay(sns_plot)"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"markdown","source":["### 4.6 Multilayer perceptron"],"metadata":{}},{"cell_type":"code","source":["#4. Multilayer perceptron classifier\nfrom pyspark.ml.classification import MultilayerPerceptronClassifier\n# specify layers for the neural network:\n# input layer of size 4 (features), two intermediate of size 5 and 4\n# and output of size 3 (classes)\nlayers = [6, 100, 100, 2]\n# create the trainer and set its parameters\nmp = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234,labelCol='FALL')\n\n\nmp1 = Pipeline(stages=[va,st,mp])\n\nmp1_fitted = mp1.fit(training)\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":54},{"cell_type":"code","source":["# auc score\nprint(\"Test Area Under ROC: \" + str(bce.evaluate(mp1_fitted.transform(test), {bce.metricName: \"areaUnderROC\"})))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test Area Under ROC: 0.6111869677204472\n</div>"]}}],"execution_count":55},{"cell_type":"code","source":["# Other evaluation method\nfrom pyspark.ml import evaluation\nevaluator = evaluation.MulticlassClassificationEvaluator(metricName=\"accuracy\",labelCol='FALL')\nevaluator.evaluate(mp1_fitted.transform(test))"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"code","source":["# try something different \nmp2 = classification.MultilayerPerceptronClassifier(seed=0,labelCol='FALL').\\\n    setStepSize(0.2).\\\n    setMaxIter(200).\\\n    setLayers([6, 100, 3])\nmp2_pipeline_fitted = Pipeline(stages=[va,st,mp2]).fit(training)\nevaluator.evaluate(mp2_pipeline_fitted.transform(test))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[88]: 0.7922794117647058</div>"]}}],"execution_count":57},{"cell_type":"markdown","source":["### 5. Other Ideas"],"metadata":{}},{"cell_type":"code","source":["#Filter those data with SL higher than 10000\nfiltered_df = df_fall.filter(df_fall['SL']< 10000)\n\nfiltered_training, filtered_test = filtered_df.randomSplit([0.8, 0.2], 0)\nfiltered_training.groupBy('FALL').agg(fn.count('*')).show()\nfiltered_test.groupBy('FALL').agg(fn.count('*')).show()"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"code","source":["rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'FALL')\nrf_pipeline_sl10000 = Pipeline(stages=[va,st,rf])\n\nrf_pipeline_sl10000_fitted = rf_pipeline_sl10000.fit(training)\n\nprint(\"Test Area Under ROC: \" + str(bce.evaluate(rf_pipeline_sl10000_fitted.transform(test), {bce.metricName: \"areaUnderROC\"})))"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"code","source":["# auc score comparation:\ny = [0.6077,0.5163,0.7364,0.8923,0.8571,0.611]\nx = ['LR','SVM','DT','RN','GBT','ANN']\nfig = sns.barplot(x=x,y=y,palette=sns.color_palette(\"Set2\", 6))\nfig.set_title('AUC score comparation with different models')\nfig.set(ylim=(0.5, 1))\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":61},{"cell_type":"code","source":["# cost time comparation with some models(mins):\ny = [4.4,109, 91,2.5]\nx = ['LR','RN','GBT','ANN']\nfig = sns.barplot(x=x,y=y,palette=sns.color_palette(\"Set2\", 4))\nfig.set_title('cost time comparation with some models (mins)')\nfig.set_ylabel('mins')\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"markdown","source":["#### Exploring with misclassification"],"metadata":{}},{"cell_type":"code","source":["# using rf_pipeline_best_fitted\ndf_predict = rf_pipeline_best_fitted.transform(test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":64},{"cell_type":"code","source":["df_predict = df_predict.select('TIME','SL','EEG','BP','HR','FALL','prediction').where(df_predict.FALL != df_predict.prediction)\ndf_predict.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+--------+--------+---+---+----+----------+\n   TIME|      SL|     EEG| BP| HR|FALL|prediction|\n+-------+--------+--------+---+---+----+----------+\n3532.39|  1896.0|  -744.0|  9| 59|   0|       1.0|\n6765.94| 10304.0| -3406.0| 44|106|   0|       1.0|\n7069.95| 15336.6|-3000.09| 81|133|   0|       1.0|\n7402.95| 14971.5|-2726.71| 70|131|   0|       1.0|\n9043.34| 96542.0| -3050.0| 21|207|   0|       1.0|\n10665.4| 79696.0| -6138.0| 64|263|   0|       1.0|\n11320.6| 45098.0| -3133.0| 21|203|   0|       1.0|\n12139.1| 53150.0| -5291.0| 21|214|   0|       1.0|\n12925.9| 68941.0| -4023.0| 22|247|   0|       1.0|\n17533.1|165772.0| -6866.0| 57|374|   0|       1.0|\n18154.0|163974.0| -8021.0| 73|398|   0|       1.0|\n22522.1|254052.0|-11569.0| 86|474|   0|       1.0|\n8429.48| 11975.9|-2613.12| 90|128|   0|       1.0|\n 4087.9| 1919.47|-1106.19|  7| 63|   0|       1.0|\n4103.81| 1905.19|-1087.44|  7| 63|   0|       1.0|\n5104.13| 3105.29| -1163.4| 44| 71|   0|       1.0|\n 5107.6| 3170.73|-1149.19| 45| 71|   0|       1.0|\n5558.18| 4195.34|-1509.93|120| 88|   0|       1.0|\n5645.97| 4298.05|-1484.78|127| 88|   0|       1.0|\n5820.29| 4137.34|-1480.86|118| 88|   0|       1.0|\n+-------+--------+--------+---+---+----+----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":65},{"cell_type":"code","source":["# histgrams of misclassification\nfig = plt.figure(figsize=(10,5))\n\npd_df_pred = df_predict.toPandas()\nplt.subplot(121)\nsns.distplot(pd_df_pred['TIME'])\nplt.title('pred_time distribution')\n\nplt.subplot(122)\nsns.distplot(pd_df['TIME'])\nplt.title('original time distribution')\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":66},{"cell_type":"code","source":["# histgrams of misclassification\nfig = plt.figure(figsize=(10,5))\n\npd_df_pred = df_predict.toPandas()\nplt.subplot(121)\nsns.distplot(pd_df_pred['SL'])\nplt.title('pred_SL distribution')\n\nplt.subplot(122)\nsns.distplot(pd_df['SL'])\nplt.title('original SL distribution')\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":67},{"cell_type":"code","source":["# histgrams of misclassification\nfig = plt.figure(figsize=(10,5))\n\npd_df_pred = df_predict.toPandas()\nplt.subplot(121)\nsns.distplot(pd_df_pred['EEG'])\nplt.title('pred_EEG distribution')\n\nplt.subplot(122)\nsns.distplot(pd_df['EEG'])\nplt.title('original EEG distribution')\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":68},{"cell_type":"code","source":["# histgrams of misclassification\nfig = plt.figure(figsize=(10,5))\n\npd_df_pred = df_predict.toPandas()\nplt.subplot(121)\nsns.distplot(pd_df_pred['BP'])\nplt.title('pred_BP distribution')\n\nplt.subplot(122)\nsns.distplot(pd_df['BP'])\nplt.title('original BP distribution')\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":69},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":70}],"metadata":{"name":"proj","notebookId":675201882838669},"nbformat":4,"nbformat_minor":0}
